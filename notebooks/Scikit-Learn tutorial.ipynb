{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn: a tutorial\n",
    "\n",
    "<img width=\"40%\" src=\"images/machine_learning_2x.png\">\n",
    "\n",
    "This is a brief tutorial on scikit-learn, which I crafted from online material, in particular from the scikit-learn webpage.\n",
    "\n",
    "Scikit-learn is a python library with a lot of machine learning algorithms implemented, both for supervised and unsupervised learning. (Credits to the cartoon go to the wonderful XKCD site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subjects that we will go through in this tutorial\n",
    "\n",
    "1. **Datasets**: loading, fetching and making toy example datasets with the `sklearn.datasets` module.\n",
    "2. **Preprocessing**: spliting into training and test sets, scaling the data values through different criteria.\n",
    "3. **Fitting supervised learning models**: the common API for all scikit-learn models.\n",
    "4. **Metrics of goodness of fit**: the common API for all metrics on goodness of fit.\n",
    "5. **Cross validation and parameter selection**: tools for efficient cross validation of models on datasets and how these can be used to get the __best__ fitting parameters.\n",
    "6. **Dimensionality reduction basics**: A small view of `sklearn.decomposition` and how to reduce features dimensionality.\n",
    "7. **Processing pipes**: Putting everything together in data processing pipes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "Scikit-learn has few built-in datasets for use. These are in the module `dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'filename', 'target', 'target_names']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "dir(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each datasets contains input data, targets, and input and target names. It may contain also additional information, e.g. raw images in case of image datasets. Pandas dataframes can be used as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the attibutes of digits  ['DESCR', 'data', 'images', 'target', 'target_names']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb113255160>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "print(\"These are the attibutes of digits \", dir(digits))\n",
    "plt.imshow(digits.images[-1], cmap=plt.cm.gray_r) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1797, 8, 8)\n",
      "[[ 0.  0. 10. 14.  8.  1.  0.  0.]\n",
      " [ 0.  2. 16. 14.  6.  1.  0.  0.]\n",
      " [ 0.  0. 15. 15.  8. 15.  0.  0.]\n",
      " [ 0.  0.  5. 16. 16. 10.  0.  0.]\n",
      " [ 0.  0. 12. 15. 15. 12.  0.  0.]\n",
      " [ 0.  4. 16.  6.  4. 16.  6.  0.]\n",
      " [ 0.  8. 16. 10.  8. 16.  8.  0.]\n",
      " [ 0.  1.  8. 12. 14. 12.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(type(digits.images[-1]))\n",
    "#these are 8x8 pixels images . \n",
    "print(digits.images.shape)\n",
    "print(digits.images[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets in scikit-learn consist of the input vector and of the target vector, passed separately to functions (and stored in separate variables). Input data is a numpy array with two dimensions. Rows contain single data points, columns cointain features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0. 10. 14.  8.  1.  0.  0.  0.  2. 16. 14.  6.  1.  0.  0.  0.  0.\n",
      "  15. 15.  8. 15.  0.  0.  0.  0.  5. 16. 16. 10.  0.  0.  0.  0. 12. 15.\n",
      "  15. 12.  0.  0.  0.  4. 16.  6.  4. 16.  6.  0.  0.  8. 16. 10.  8. 16.\n",
      "   8.  0.  0.  1.  8. 12. 14. 12.  1.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can in principle reshape the image to trasnform in into a dataset\n",
    "#this transforms a single input point in a row\n",
    "print(digits.images[-1].reshape((1, -1))) \n",
    "# this transforms the whole input images into a row\n",
    "digits.images.reshape((digits.images.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#though the dataset is already prepared!\n",
    "print(digits.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "1. Find the list of the available datasets\n",
    "2. Fetch the boston housing dataset and create a pandas.DataFrame with it (add the target values as a column in the DataFrame)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Operations on  Datasets\n",
    "A cool thing of scikit-learn is that is has functions to perform routine operations on datasets, including: \n",
    "* generating Test and Train datasets. The relevant function is `train_test_split` from the module `model_selection`.\n",
    "* Standardising input data. The function scale of the module `preprocessing` provides a quick and easy way to perform this operation on a single array-like dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#default test_size is 0.25\n",
    "#random state is the seed of the random sampler used to generate test and train datasets\n",
    "#data and target must have the same number of rows, i.e. same first coordinate of shape\n",
    "print(iris.data.shape,iris.target.shape)\n",
    "iris_X_train, iris_X_test, iris_y_train, iris_y_test = \\\n",
    "    train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very important parameter of `train_test_split` is `stratify`. If left as `None`, `train_test_split` will uniformly randomly select rows to use in the train and test sets. This criteria may produce unbalanced sets (i.e. the label distribution may be different between the train and test sets). For very big datasets, or datasets are well balanced to begin with, this is usually not a problem; but when the datasets are smaller, this can have serious consequences. For example, it may happen that some labels can be completely abscent in the train or test set, and the learnt models will work poorly.\n",
    "\n",
    "If you supply an array to `stratify`, the train and test split is done on the rows corresponding to each of the unique values of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without stratify\n",
      "original\n",
      "{0: 0.3333333333333333, 1: 0.3333333333333333, 2: 0.3333333333333333}\n",
      "---\n",
      "train\n",
      "{0: 0.37777777777777777, 1: 0.3, 2: 0.32222222222222224}\n",
      "---\n",
      "test\n",
      "{0: 0.26666666666666666, 1: 0.38333333333333336, 2: 0.35}\n",
      "---\n",
      "\n",
      "Using stratify\n",
      "original\n",
      "{0: 0.3333333333333333, 1: 0.3333333333333333, 2: 0.3333333333333333}\n",
      "---\n",
      "train\n",
      "{0: 0.3333333333333333, 1: 0.3333333333333333, 2: 0.3333333333333333}\n",
      "---\n",
      "test\n",
      "{0: 0.3333333333333333, 1: 0.3333333333333333, 2: 0.3333333333333333}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# First lets see the label distribution for the train and test sets without stratification.\n",
    "# np.unique(iris.target, return_counts=True)\n",
    "iris_X_train, iris_X_test, iris_y_train, iris_y_test = \\\n",
    "    train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "print('Without stratify')\n",
    "a = {'original': iris.target,\n",
    "     'train': iris_y_train,\n",
    "     'test': iris_y_test}\n",
    "for kind, vals in a.items():\n",
    "    print(kind)\n",
    "    print({label: c / len(vals) for label, c in zip(*np.unique(vals, return_counts=True))})\n",
    "    print('---')\n",
    "\n",
    "# Now lets see what happens when we use stratify\n",
    "\n",
    "iris_X_train2, iris_X_test2, iris_y_train2, iris_y_test2 = \\\n",
    "    train_test_split(iris.data, iris.target, test_size=0.4, random_state=0,\n",
    "                     stratify=iris.target)\n",
    "a = {'original': iris.target,\n",
    "     'train': iris_y_train2,\n",
    "     'test': iris_y_test2}\n",
    "print('\\nUsing stratify')\n",
    "for kind, vals in a.items():\n",
    "    print(kind)\n",
    "    print({label: c / len(vals) for label, c in zip(*np.unique(vals, return_counts=True))})\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "1. Load the digits dataset, and split it in train and test sets (20% of the data must be in the test), stratified according to the target value.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non standardised\n",
      " [[6.  3.4 4.5 1.6]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.6 2.9 3.6 1.3]]\n",
      "Standardised\n",
      " [[ 0.18206758  0.71103882  0.45664061  0.55799544]\n",
      " [-1.17402201  0.00522823 -1.10334891 -1.19530695]\n",
      " [-0.04394735 -0.93585257  0.77939706  0.9337031 ]\n",
      " [-0.26996228 -0.93585257  0.29526238  0.18228779]\n",
      " [-0.26996228 -0.46531217 -0.02749407  0.18228779]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "iris_X_scaled = preprocessing.scale(iris_X_train)\n",
    "print(\"Non standardised\\n\",iris_X_train[:5,:])\n",
    "print(\"Standardised\\n\",iris_X_scaled[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer API and Preprocessing\n",
    "Scikit-learn has some API/ interfaces which are very useful to automate the learning process.\n",
    "As data preprocessing has an important role in learning - typically dataset are standardised or normalised in some way - there several classes implementing the Transformer API. \n",
    "\n",
    "The two relevant methods of a transformer object are `fit()` and `transform()`. The first one is used to train the transformer, e.g. define the standardisation for each feature, the second one to apply the transformation to novel data. Transformer objects can be trained on the train datasets and then applied to test datasets, hence they should be the methods of choice.  \n",
    "\n",
    "Data preprocessing is usually performed through the `Scaler` objects, which are of several types:\n",
    "* `StandardScaler` performs classic standardisation;\n",
    "* `MinMaxScaler` normalises data into [0,1], where 0 is the minimum and 1 is the maximum of each feature, but different ranges can be specified as well;\n",
    "* `MaxAbsScaler` divides each feature for the absolute value, hence data is scaled in [-1,1];\n",
    "* `RobustScaler` deals better with data with outliers, as it removes the median and scales the data according to the quantile range;\n",
    "\n",
    "Other methods perform non-linear transformations:\n",
    "* `QuantileTransformer` performs a non-linear transformation using quantiles. Better for outliers, but being non-linear, it breaks the correlation. \n",
    "* `Normalizer` scales individual samples to have unit norm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non standardised\n",
      " [[5.8 2.8 5.1 2.4]\n",
      " [6.  2.2 4.  1. ]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [5.  3.4 1.5 0.2]]\n",
      "Standardised\n",
      " [[-0.04394735 -0.70058237  0.77939706  1.55988252]\n",
      " [ 0.18206758 -2.11220356  0.1876769  -0.19341987]\n",
      " [-0.38296975  2.59320041 -1.21093439 -1.19530695]\n",
      " [ 1.65116464 -0.46531217  1.42490997  0.80846721]\n",
      " [-0.94800707  0.71103882 -1.15714165 -1.19530695]]\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(iris_X_train)\n",
    "iris_X_scaled = scaler.transform(iris_X_scaled)\n",
    "iris_X_test_scaled = scaler.transform(iris_X_test)\n",
    "\n",
    "print(\"Non standardised\\n\",iris_X_test[:5,:])\n",
    "print(\"Standardised\\n\",iris_X_test_scaled[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non standardised\n",
      " [[5.8 2.8 5.1 2.4]\n",
      " [6.  2.2 4.  1. ]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [5.  3.4 1.5 0.2]]\n",
      "Standardised\n",
      " [[0.41666667 0.27272727 0.68965517 0.95833333]\n",
      " [0.47222222 0.         0.5        0.375     ]\n",
      " [0.33333333 0.90909091 0.05172414 0.04166667]\n",
      " [0.83333333 0.31818182 0.89655172 0.70833333]\n",
      " [0.19444444 0.54545455 0.06896552 0.04166667]]\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler().fit(iris_X_train)\n",
    "iris_X_scaled = scaler.transform(iris_X_train)\n",
    "iris_X_test_scaled = scaler.transform(iris_X_test)\n",
    "\n",
    "print(\"Non standardised\\n\",iris_X_test[:5,:])\n",
    "print(\"Standardised\\n\",iris_X_test_scaled[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MinMaxScaler in module sklearn.preprocessing.data:\n",
      "\n",
      "class MinMaxScaler(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      " |  Transforms features by scaling each feature to a given range.\n",
      " |  \n",
      " |  This estimator scales and translates each feature individually such\n",
      " |  that it is in the given range on the training set, i.e. between\n",
      " |  zero and one.\n",
      " |  \n",
      " |  The transformation is given by::\n",
      " |  \n",
      " |      X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
      " |      X_scaled = X_std * (max - min) + min\n",
      " |  \n",
      " |  where min, max = feature_range.\n",
      " |  \n",
      " |  This transformation is often used as an alternative to zero mean,\n",
      " |  unit variance scaling.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  feature_range : tuple (min, max), default=(0, 1)\n",
      " |      Desired range of transformed data.\n",
      " |  \n",
      " |  copy : boolean, optional, default True\n",
      " |      Set to False to perform inplace row normalization and avoid a\n",
      " |      copy (if the input is already a numpy array).\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  min_ : ndarray, shape (n_features,)\n",
      " |      Per feature adjustment for minimum.\n",
      " |  \n",
      " |  scale_ : ndarray, shape (n_features,)\n",
      " |      Per feature relative scaling of the data.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *scale_* attribute.\n",
      " |  \n",
      " |  data_min_ : ndarray, shape (n_features,)\n",
      " |      Per feature minimum seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_min_*\n",
      " |  \n",
      " |  data_max_ : ndarray, shape (n_features,)\n",
      " |      Per feature maximum seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_max_*\n",
      " |  \n",
      " |  data_range_ : ndarray, shape (n_features,)\n",
      " |      Per feature range ``(data_max_ - data_min_)`` seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_range_*\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.preprocessing import MinMaxScaler\n",
      " |  >>>\n",
      " |  >>> data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
      " |  >>> scaler = MinMaxScaler()\n",
      " |  >>> print(scaler.fit(data))\n",
      " |  MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      " |  >>> print(scaler.data_max_)\n",
      " |  [ 1. 18.]\n",
      " |  >>> print(scaler.transform(data))\n",
      " |  [[0.   0.  ]\n",
      " |   [0.25 0.25]\n",
      " |   [0.5  0.5 ]\n",
      " |   [1.   1.  ]]\n",
      " |  >>> print(scaler.transform([[2, 2]]))\n",
      " |  [[1.5 0. ]]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  minmax_scale: Equivalent function without the estimator API.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      " |  transform.\n",
      " |  \n",
      " |  For a comparison of the different scalers, transformers, and normalizers,\n",
      " |  see :ref:`examples/preprocessing/plot_all_scaling.py\n",
      " |  <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MinMaxScaler\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, feature_range=(0, 1), copy=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Compute the minimum and maximum to be used for later scaling.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          The data used to compute the per-feature minimum and maximum\n",
      " |          used for later scaling along the features axis.\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Undo the scaling of X according to feature_range.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          Input data that will be transformed. It cannot be sparse.\n",
      " |  \n",
      " |  partial_fit(self, X, y=None)\n",
      " |      Online computation of min and max on X for later scaling.\n",
      " |      All of X is processed as a single batch. This is intended for cases\n",
      " |      when `fit` is not feasible due to very large number of `n_samples`\n",
      " |      or because X is read from a continuous stream.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y\n",
      " |          Ignored\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Scaling features of X according to feature_range.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          Input data that will be transformed.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Each scaler has some options, use help or refer to scikit-learn manual!\n",
    "help(preprocessing.MinMaxScaler) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "1. Fetch the california housing dataset. Grab the 'MedInc' and 'AveOccup' feature data values. Plot the joint distribution after scaling them using the `StandardScaler`, the `QuantileTransformer` and the `Normalizer`. For a thorough comparison you can look up [here](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning\n",
    "Regression and classification in scikit-learn follow a similar pattern. Different methods are based on instances of the `Estimator` class, which provides methods to fit the estimator - `fit()`, to predict on new data - `predict()`, and to score the model - `score()`.   \n",
    "\n",
    "We will start with an example on linear regression, on a diabetis dataset. The diabetes dataset consists of 10 physiological variables (age, sex, weight, blood pressure) measure on 442 patients, and an indication of disease progression after one year.\n",
    "\n",
    "For linear regression, there is the module `linear_model`, which has several implementation of linear regression, the basic one and some regularised versions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_X_train, diabetes_X_test, diabetes_y_train, diabetes_y_test \\\n",
    "    = train_test_split(diabetes.data, diabetes.target, random_state=0)\n",
    "scaler = preprocessing.StandardScaler().fit(diabetes_X_train)   \n",
    "diabetes_X_train = scaler.transform(diabetes_X_train)\n",
    "diabetes_X_test = scaler.transform(diabetes_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -2.08201439  -9.93774758  28.8548248   14.33603969 -26.52011217\n",
      "  12.38436283  -0.42239104   6.59599005  34.458465     1.41463977]\n",
      "Explained variance score: 0.35940090989715545\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "regressor = linear_model.LinearRegression()\n",
    "regressor.fit(diabetes_X_train, diabetes_y_train)\n",
    "print(regressor.coef_)\n",
    "print(\"Explained variance score:\", regressor.score(diabetes_X_test, diabetes_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explained variance regression score measures the fraction of variance which is captured by the regression models. \n",
    "If yp is the estimated target output, and y the corresponding (correct) target output, and Var is the Variance, the square of the standard deviation, then the explained variance is estimated as follow:\n",
    "\n",
    "$$explained\\_variance(y,yp) = 1 - \\frac{Var[y-yp]}{Var[y]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb113075f28>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We can use predict on a matrix, and get a vector of predictions. \n",
    "y_predict = regressor.predict(diabetes_X_test)\n",
    "plt.figure()\n",
    "plt.scatter(diabetes_y_test,y_predict)\n",
    "plt.plot(np.linspace(0,350,100),np.linspace(0,350,100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the module `linear_model`, we have several linear classifiers, including some that are regularised, in particular `Ridge` and `Lasso` regression. These can be used similarly to the linear classifier above, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance score: 0.35920949931140134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb11305f940>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regressor = linear_model.Ridge(alpha=0.1)\n",
    "regressor.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "print(\"Explained variance score:\", regressor.score(diabetes_X_test, diabetes_y_test))\n",
    "\n",
    "y_predict = regressor.predict(diabetes_X_test)\n",
    "plt.figure()\n",
    "plt.scatter(diabetes_y_test,y_predict)\n",
    "plt.plot(np.linspace(0,350,100),np.linspace(0,350,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Ridge and Lasso regression depend on a coefficient of regularization, which should be estimated in the learning process. Scikit-learn exposes methods that do ridge/lasso regression and cross-validation in a single step: `RidgeCV` and `LassoCV` (there are more CV methods for Lasso, see the documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 1.023292992280754\n",
      "Explained variance score: 0.35573555529892387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb111dbd400>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xl4VOX1wPHvIQkhYQubCgFkB9nBCChqBa0gVgF3W5eqlS5aW9sCwQ2sWqlWqf7qUloXrNaNXVBxw6IoahBIQtgia8ISEBKWLGR5f3/MDQ7J7DN3tpzP8+TJzJ07M2fuJOe+97zvfa8YY1BKKRW/GkU6AKWUUvbSRK+UUnFOE71SSsU5TfRKKRXnNNErpVSc00SvlFJxThO9UkrFOU30SikV5zTRK6VUnEuMdAAAbdu2NV26dIl0GEopFVNWr159wBjTztt6UZHou3TpQlZWVqTDUEqpmCIiO3xZT0s3SikV5zTRK6VUnNNEr5RScU4TvVJKxTlN9EopFee8JnoRaSIiX4vIOhFZLyIPWstfFpFtIrLW+hlsLRcReVpE8kUkW0SG2v0hlFJKuefL8MoKYLQx5qiIJAGfi8h71mOTjTFz66x/CdDT+hkOPGf9VkopFQFeW/TG4ah1N8n68XT9wfHAK9bzVgFpItI++FCVUip+VFbX8Oyn+azbVWz7e/lUoxeRBBFZCxQBHxpjvrIeesQqz8wSkWRrWTqwy+npBdayuq85SUSyRCRr//79QXwEpZSKLbmFJUx4ZiWPvb+J93L32v5+PiV6Y0y1MWYw0BEYJiL9gWlAH+AsoDUw1VpdXL2Ei9ecbYzJMMZktGvn9QxepZSKeeWV1Ty+bCPjn1nJvsMVPPezoWRe0sf29/VrCgRjTLGIfAqMNcb8zVpcISIvAX+y7hcAnZye1hHYHWygSikVy7K2H2TKvGy27j/GlUM7cv9PziAttXFY3tuXUTftRCTNup0CXARsrK27i4gAE4Bc6ymLgZus0TcjgBJjzB5boldKqSh3tKKK6YtyufqfX1JRWcMrtw7jiWsGhS3Jg28t+vbAHBFJwLFjeMsYs0REPhGRdjhKNWuBX1nrvwuMA/KBUuCW0IetlFLR73+b93PP/Bx2l5Rx89ldmDymN02Twz+XpNd3NMZkA0NcLB/tZn0D3BF8aEopFZuKS4/z0JINzPu2gO7tmvL2L88mo0vriMUTFdMUK6VUvHg3Zw8PLMrlUGkld47qwZ2je9AkKSGiMWmiV0qpECg6XM4Di9bz/vq99E9vwZxbh9GvQ8tIhwVooldKqaAYY3h7dQEPL8mjvKqGqWP7cPt5XUlMiJ6pxDTRK6VUgHYdLOWeBTl8tuUAw7q0ZuaVA+jWrlmkw6pHE71SSvmpusbwypfbeez9TTQSeGh8P342/HQaNXJ1vmjkaaJXSik/5BcdYcrcbL7dWcwFvdvxyMQBpKelRDosjzTRK6WUDyqra3j+0+/4v0/ySU1OYNa1g5gwOB3HOaPRTRO9Ukp5kVNQwuS569i49wg/GdieGZf3o22zZO9PjBKa6JVSyo3yympmfbSZf63YSttmycy+8Uwu7ndapMPymyZ6pZRy4ettB5k6L5ttB45x3VmdmDbuDFqmJEU6rIBooldKKSdHyit57P1N/GfVDjq1TuG1XwxnZI+2kQ4rKJrolVLKsnxTEffOz2HP4XJuO7crf7y4F6mNYz9Nxv4nUEqpIB08dpyHluSxYE0hPU9pxrxfn8PQzq0iHVbIaKJXSjVYxhiW5uxh+qL1lJRVcteFPbljVHeSEyM7CVmoaaJXSjVI+w6Xc9/CXD7M28fAji159RfDOaN9i0iHZQtN9EqpBsUYw1tZu3h46QaOV9Vwz7g+3DoyuiYhCzVN9EqpBmPn96Vkzs/mi+++Z3jX1vz1yoF0ads00mHZThO9UiruVdcYXlq5jSc+2ExCI+EvEwdw3VmdonYSslDTRK+Uimub9zkmIVu7q5gL+5zCwxP7075ldE9CFmpeE72INAFWAMnW+nONMdNFpCvwBtAa+Ba40RhzXESSgVeAM4HvgWuNMdttil8ppVw6XlXDc59+xz+Wb6F5kySeum4wlw/qEBOTkIWaLy36CmC0MeaoiCQBn4vIe8AfgFnGmDdE5HngNuA56/chY0wPEbkO+CtwrU3xK6VUPet2FTNlbjab9h3h8kEdmH5ZX9rE0CRkoea1m9k4HLXuJlk/BhgNzLWWzwEmWLfHW/exHr9QGuIuVCkVdmXHq/nLuxuY+OxKSsoq+fdNGTx9/ZAGneTBxxq9iCQAq4EewDPAd0CxMabKWqUASLdupwO7AIwxVSJSArQBDtR5zUnAJIDOnTsH9ymUUg3el999z7T52Wz/vpTrh3Vm2rg+tGgSm5OQhZpPid4YUw0MFpE0YAFwhqvVrN+uWu+m3gJjZgOzATIyMuo9rpRSvjhcXsnM9zby3692cnqbVP57+3DO6R7bk5CFml+jbowxxSLyKTACSBORRKtV3xHYba1WAHQCCkQkEWgJHAxdyEop5fDxhn3cuyCXoiPl3H5eV/7w496kNI6v6QtCwWuNXkTaWS15RCQFuAjYACwHrrJWuxlYZN1ebN3HevwTY4y22JVSIfP90Qruen0Nt83JomVKEvN/M5J7L+2rSd4NX1r07YE5Vp2+EfCWMWaJiOQBb4jIw8Aa4AVr/ReA/4hIPo6W/HU2xK2UaoCMMSxet5sH38njSHklv7+oJ7+5oAeNE+N3+oJQ8JrojTHZwBAXy7cCw1wsLweuDkl0Sill2VNSxn0Lcvl4YxGDO6Xx2FUD6XVq80iHFRP0zFilVFSrqTG8/s1OHn13I1U1Ndx36RncMrIrCQ1k+oJQ0ESvlIpa2w8cI3N+Nqu2HuSc7m2YecVAOrdJjXRYMUcTvVIq6lRV1/CiNQlZ44RGzLxiANee1alBTl8QCprolVJRZePew0ydm826ghIuOuNUHp7Qn9NaNol0WDFNE71SKipUVFXzzPLveHZ5Pi1TkvjHT4dw6YD22ooPAU30SqmIW7PzEFPmZrOl6CgTh6TzwE/60qpp40iHFTc00SulIqb0eBVPfLCZF1du47QWTXjp52cxqs8pkQ4r7miiV0pFxBf5B8icn8POg6XcMKIzU8f2oblOQmYLTfRKqbAqKavk0Xc38MY3u+jSJpU3Jo1gRLc2kQ4rrmmiV0qFzYd5+7hvYQ77j1Twyx914+6LetEkSeensZsmeqWU7Q4crWDG4vUsyd5Dn9Oa86+bMhjYMS3SYTUYmuiVinML1xTy+LJN7C4uo0NaCpPH9GbCkHTvTwwBYwwL1xby4Dt5lFZU88cf9+JXF3QnKUEnIQsnTfRKxbGFawqZNj+HsspqAAqLy5g2PwfA9mS/u7iMexfksHzTfoZ2TuOvVw6kp05CFhGa6FXERbLFGe8eX7bpRJKvVVZZzePLNtm2jWtqDK99vZOZ726gxsD0y/py09lddBKyCNJEryIqki3OhmB3cZlfy4O1df9RMufl8PX2g5zboy2PXjGATq11ErJI00SvIioSLc6GpENaCoUuknqHtJSQvk9VdQ3//nwbsz7cTHJiIx67aiBXn9lRpy+IEproVUSFu8XZ0Ewe0/ukIyaAlKQEJo/pHbL3yNt9mCnz1pFbeJgx/U7lofH9OaWF50nItFwXXproVUSFq8XZUNUmTzuSakVVNf/4JJ/nPv2OtNQknv3ZUMYNaO/1eVquCz9N9CqiwtHibOgmDEkPeQJdveMQU+dlk190lCuHduT+n5xBWqpvk5BpuS78vA5mFZFOIrJcRDaIyHoR+Z21fIaIFIrIWutnnNNzpolIvohsEpExdn4AFdsmDEnn0SsGkJ6WggDpaSk8esUA/YePUscqqpixeD1XPf8FZcermXPrMJ64ZpDPSR60XBcJvrToq4A/GmO+FZHmwGoR+dB6bJYx5m/OK4tIX+A6oB/QAfhIRHoZY07ehStlsaPFqULvsy37mTY/h4JDZdx89ulMHtuHZsn+FwW0XBd+Xr8lY8weYI91+4iIbAA8/VeOB94wxlQA20QkHxgGfBmCeJVqcCLdcVlSWslDS/OYu7qAbu2a8vavzuasLq0Dfj0t14WfX7tjEekCDAG+AkYCd4rITUAWjlb/IRw7gVVOTyvA845BKeVGpDsu38/dw/2L1nPw2HF+c0F37rqwZ9CTkNnZQaxc8znRi0gzYB7we2PMYRF5DngIMNbvJ4BbAVcDZ42L15sETALo3Lmz/5Er1QBEquOy6Eg50xet573cvfRt34KXfn4W/dNbhuz1tVwXXj4lehFJwpHkXzPGzAcwxuxzevxfwBLrbgHQyenpHYHddV/TGDMbmA2QkZFRb0eglAp/x6UxhnnfFvLQkjzKKquZPKY3k87vppOQxTiviV4cp7a9AGwwxjzptLy9Vb8HmAjkWrcXA/8VkSdxdMb2BL4OadRKNRDh7LgsOFTKPQtyWbF5Pxmnt2LmlQPpcUozv14j0v0JyjVfWvQjgRuBHBFZay27B7heRAbjKMtsB34JYIxZLyJvAXk4RuzcoSNulApMODoua2oM/1m1g7++vxGAP4/vxw3DT6eRn5OQRbo/IZTibYclxkS+apKRkWGysrIiHYZSUcnOpJNfdJTMedlk7TjE+b3a8ZeJ/enYKrBJyEbO/MTl0Ud6WgorM0cHG2rY1N1hgWPnGo3nd4jIamNMhrf19MxYpaKcHR2XldU1zF6xlac+2kJK4wSeuHoQVwxND2oSsng5ESoez9zVRK+UjaKxBJBbWMKUudnk7TnMpQPaM+PyfrRrnhz068bLiVDxssNypoleKZv4W7O2e6dQXlnNUx9vYfaKrbRu2pjnbziTsf1PC9nrx8uJUPGyw3KmiV7VE42t0FjkTwnA7o7Mb7YfZOrcbLYeOMY1GR25d1xfWqYmBf26zuLlRKh42WE500SvThJPIycizZ8SgF114aMVVTz2/kZe+XIHHVul8OptwzlwtIJxT39mSzJ21Z8Qaw2HeNlhOdNEr04Sjx1RkeJPCcCOuvD/Nu/nnvk57C4p45aRXfjTxb35MG9fWHfksdpwiLczd/V0N3WSeOyIipTJY3qTUmdeGHclAHf130DqwsWlx/nDW2u5+cWvaZLUiLm/Opvpl/WjaXKixx25HcL9fso1bdGrk8RjR1So+FuC8KcEEIq6sDGG93L38sCiXIpLK/nt6B7cMarHSZOQhXtHrg2H6KCJXp0kHjuiQsGfEkQgNelg68JFh8u5f1Euy9bvo396C165dTh9O7Sot164d+TacIgOmujVSeKxIyoUfO27CKYmHUhd2BjD26sLeHhJHhVVNWRe0odfnNuVRDeTkIV7R64Nh+igiV7VE28dUc4CHQHiawkinJ3Zuw6WMm1+Dp/nH2BYl9bMvHIA3dp5noQs3DtybThEB030qsEIprXtawkiHDXp6hrDnC+28/iyTSQ0Eh6e0J+fDuvs8yRk4d6Rx0LDIdaGgPpLR92oBiOYESC+jqBxV3tOS01i5MxP6Jq5lJEzP2HhmkI/o3fYsu8IVz//BX9eksfwbq354O7zuWGE/zNNqh/UNgAKi8sw/NAACPQ7ikaa6FWDEUxre8KQdB69YgDpaSkIjhkZXc1m6GqHkJQgHC2vCiqRVFbX8H8fb+HSpz9n24Fj/P3awbz087O0UzMEGsIQUC3dqAYj2BEgvpQgXNWkj1VUUVxWedJ6/tTtswuKmTI3m417j/CTgY5JyNo2C34SMuXQEIaAaqIPs3ivBUYDd9s4XCNA6u4QumYudbmet0RSXlnNrA8386/PttKueTL/uimDH/c9NaSxqoYxBFQTfRjF6ung0c45saelJnG0vIrKGscFdVxt43DvaANJJKu2fk/mvGy2f1/KdWd1Ytq4M2iZEtpJyJRDQxgCqok+jHQemdCru/M8VFpZbx3nbRyJESD+JJIj5ZXMfG8jr321k06tU/jvL4ZzTo+24Qw35gR7lNwQhoBqog+jYGqBWvJxzdXO0xW76q2+fC+19x98Z/2JHVFyYv1xEMs3FnHPghz2Hi7n1pFd+dOYXqQ21n9RT0J1lBwLQ0CD4XXUjYh0EpHlIrJBRNaLyO+s5a1F5EMR2WL9bmUtFxF5WkTyRSRbRIba/SFiRaATVzWE4V+B8jWB21Fv9fd7Ka+sOXG7uKzyxLoHjx3n7jfXcsvL39AsOZF5vz6HBy7rq0neBw1hxEwo+DK8sgr4ozHmDGAEcIeI9AUygY+NMT2Bj637AJcAPa2fScBzIY86Rvkzm6GzhvjHvHBNoU/jzn1J4HbVW/35Xtyt++A76/nxk//jnXW7uWt0D5bcdS5DO7cKeazxqiGMmAkFr4neGLPHGPOtdfsIsAFIB8YDc6zV5gATrNvjgVeMwyogTUTahzzyGOTrWOy6Gtofsz8tZXfj1tNSkvzaxoHw53txt+6h0krSW6Ww5K5z+cPFvUlOTHC5nnItlNM7xzO/jg1FpAswBPgKONUYswccOwMROcVaLR3Y5fS0AmvZnmCDjQeB1AIbwvAvZ/50WoejI81dHd6f78Xdui2aJDL/1+e4nYRMedYQRsyEgs+JXkSaAfOA3xtjDou4PeXa1QPGxetNwlHaoXPnzr6G0SA1tD9mf49g7OxI89TZ58/3MnlMb6bOy6ai6oc6fXJiI/48vr+tST7eO/EbwoiZUPAp0YtIEo4k/5oxZr61eJ+ItLda8+2BImt5AdDJ6ekdgd11X9MYMxuYDZCRkVFvR6B+0ND+mCNxBOMuIXo6uliZORrw/r1U1xgOHK2gxhgER6unQ8smTBnbx9bvMFbP2wjkAi/R/HmigddEL46m+wvABmPMk04PLQZuBmZavxc5Lb9TRN4AhgMltSUeFbiG9Mcc7iMYTwnR29GFt+9l094jTJ2XzdpdxVzY5xQentif9i3DU3KLxfM2YnXnFO18adGPBG4EckRkrbXsHhwJ/i0RuQ3YCVxtPfYuMA7IB0qBW0IasYp7ro5gRvVpx+PLNnH3m2tDfkTjKSEGenRxvKqGZz/N55nl+TRvksRT1w3m8kEd8FDyDLlY68RfuKaQP761jmpz8gF+tO+cYoHXRG+M+RzXdXeAC12sb4A7goxLxZFAL61Xu47drTxPCXHWtYP9PrpYt8sxCdmmfUcYP7gDD/ykL20iMAlZLHXi137HdZN8rWjdOcUK7epXtgrFyV52n0fgaYieP0Niy45X88jSPCY+u5KSskpeuDmDp64bEpEkD4GftxEJ3s5wrv2OfD2/Qp1MT71TtgpFndjuEoS3PgFf+ke++O4A0+bnsOP7Un46vDOZl/ShRZPITkIWS534nr7L2u9C6/eB00SvbBWKJG13CSKYhHi4vJJH393I61/v5PQ2qbx++wjO7t4mJHGFgl2d+KEetunuO04QOXEENXLmJzHXuRwtNNErW4UiSYdyFI67BFU3IS5cU8iQP39wYhKytJQkZlze76R1Pt6wj3sX5FJ0pJxJ53fj7ot6kdI4Ie7HrtvRsnb3HTuXyWKtczmaaKJXtgpFkg5VCcLXBLVwTSGT566jsvqHjsHiskomv70OgPN6tuXBd/JYvG43vU9tzj9vPJNBndK8vkcoPkMwQrUDsmPYpi/fcSx1LkcbMW56ucMpIyPDZGVlRToMZZNoaeGOnPmJy0SRnpZy4uQnT+sBtEpNQkQ4Ul7JnaN68usLutPYacphd89NS0mioqrGY4vVm2C2Y90dUCDvX6tr5tL6p7rjGJq3bealfr2WP0L5GeKFiKw2xmR4W09b9Mp20XKyl6+H/p5KAYdKKxnUKY3HrxpIr1Ob+/weda8ZC/61goMtl/jSCvd1RxKplnUsdS5HG030qsHwNUG5Ww+gZZMk5v/6HBIauT61xNNzXfG1vhxsucTbTs6fHUkk516KlkZDrNFx9KrB8DauvHaMtrtEnSjw4Ph+bpO8p/dolep6qKWvreBgOyK9Tefrz7kKgU63rSJHW/QqIMHW3SNRt/d06O+q/uusZZNEHhzf36czel29BxBUKzjYcom3Vng0zRiqQk8TvfKbP4f5rhI6ELETX9wlKHdnZp7Wogmr7qk300dA71H7PoHs3IItl3irb+uIlvimo26U33wdveJulERyYiOXnZN1nx9OXTKXulxu90gSf9h5FKQjWmKTjrpRtvH1MN9d3dddeSRSJ758u/MQiY2Eqpr6jZ5QtGhDlaDtLJd4a/FHyxBZFRhN9MpvaalJJ84Yrbvcmb+JO5ikWjcRjerTjuUb93tMTKXHq/jbss289MU2WqYkUVpRzfHqH64AVbejNpBEF0vzs7jbkcTSZ1Cu6agb5Td31b66y/1J3AL1Rr/4OkOhqxkyX1210+OMmZ9vOcDFs1bw4spt/Gx4Zz6bMorHrhrociRJMDNw2j3zZjjEw2do6LRFr/xW4qK+7mq5qw5Edwy4HP1St/XoqmXtbYpb+CExjepzCo8szeOtrAK6tm3Km5NGMLxbmxOv72tHra9j2ONhfhY7PoOWgsJLE73ym68jNFzVfY9VVLnsiAVHJ++xiiqPrUdXOwFfdiS16//4yf9x4GgFvzy/G3f/uBdN6ox5dyWYROduW7VMiewUxv4I9YgcLQWFn5ZulN9cnRQkOP5h65ZaJgxJZ2XmaLbNvJSVmaOZcXm/es+tVVhc5nYnUFhcxh/fWudyJ5Dgx+X5WjdtzMI7RjJt3Bk+JXnwfrKRJ5PH9CbJxQlWx45XxcxFM0J9ARMtBYWfJnrlN+czI8GR5GvL897q13Wf6ysBt5eZqzbG7c7D2bj+p/HOb89lYMc0v947mEQ3YUg6zZrUP3CurDYxk9hCfSas3eUsvQpVfVq6UQGprWe7GlPvrX5d+1x3syDW5bwjcSXdqVZfWyIa1rUV7+bspaKqhsYJjfjDxb341Y+6+/z56sYLgZ/sVOxihBLEVp0+lEM77Tw5S8tCrnlN9CLyIvAToMgY099aNgO4HdhvrXaPMeZd67FpwG1ANXCXMWaZDXErH9nd6WVH/bpVahKpjRNPxOxpkrDalnVtIqqpMbz21Q5mvreRRiJMv6wvN53dxeP8NL4IJtHpWacns3NSNDvmyo8HvrToXwb+AbxSZ/ksY8zfnBeISF/gOqAf0AH4SER6GWN86y1TIeXPhTYC3RkEk8Tc/cNPv+yHKzktXFPI3W+uddmid77MHMDW/UfJnJfD19sPcl7Ptvxl4gA6tU716XPYKdSJLdZHrNg53XA8jHKyg9dEb4xZISJdfHy98cAbxpgKYJuI5APDgC8DjlAFzF3r5sF31p/4J0tLTeJoeRWV1lmhvgxndP6HDCaJ+fIP//iyTW4vcvHENYOYMCSdquoa/vXZNmZ9tJkmiY14/KqBXHVmR8SPTlo7hTKxxUtpwq6zfPXoybVgavR3ishNQBbwR2PMISAdWOW0ToG1rB4RmQRMAujcuXMQYSh33LViDpVWnjiz1dUZrt6GM8IPSSXYJObtH97dZ6gdd5+3+zBT5q0jt/AwY/udxp8n9OOU5k18eu9wClVi09KEZ5GcKz+aBZronwMewvH/9hDwBHArjoZWXS770Ywxs4HZ4JjULMA4lAf+XgTD2e7iMp+Tip1zsLhtobVswt+WbeL5/31HWmpjnvvZUC4Z0N6WGEIp2LKLliY806tQuRZQojfG7Ku9LSL/ApZYdwuATk6rdgR2BxydCsrkMb3d1re96ZCWEhVJxVULrXFCI6pqDP9Yns+VQzty/0/OIC21cdhiiuS8N1qa8E7nyq8voHH0IuLcdJoI5Fq3FwPXiUiyiHQFegJfBxeiCtSEIekBJfnaQ91gThQKlbrj7ps2TqCyuoakhEbMuXUYT1wzKOgk78+460jMe+McX+nxqnonYGlpQnnjy/DK14ELgLYiUgBMBy4QkcE4yjLbgV8CGGPWi8hbQB5QBdyhI24iK92H8k1SgtC0cSIlZZX1WqjRUO+cMCSd1k0bM21+DrtLyrjx7NOZMrYPzZKDPw3EVSv77jfXkrXjIA9PGFBv/XDPe1M3vkOllSQlCGkpSS6/L6Vc8WXUzfUuFr/gYf1HgEeCCUqFjqvSR1IjoVmTRIpLPSeKaKh3lpRW8tDSPOauLqBbu6a8/cuzKThUxphZK0ISk6vEbYDXVu0k4/TW9V7XjvMGPB0huYqvstrQNDmRtdMvdvu8WB+CqUJLz4yNc3aPirHT+7l7uH/Reg4eO84do7rz29E9eT93b0iHF3oa1eOqlW7HeQOejpBCcRQQq0MwVehooo8SnlpgwbbOYq1zquhIOdMXree93L30bd+Cl35+Fv3TWwKhH17oaWSSq2Rq93kDvsbn71GADsFs2DTRh4G3RO2pBQaRu5B2uBljmPdtIQ8tyaOsspopY3tz+3ndSEr4YcxAqEcCeRqZ5CqZhvsIKVxHASq+aaK3mS+H0d5GYzSE1tmug6XcsyCHz7YcIOP0Vvz1qoF0b9es3nqhHl44YUg6WTsO8tqqnScle0/JNJxHSOE6ClDxTYy768KFUUZGhsnKyop0GLZwNbsjOOZpqTHGY+mgdhCduykAts28NGRxRkpNjeE/q3bw1/c3IsDUS/pww/DTaeRmErK6O05wJOVgps2tfd146by0axup6CMiq40xGd7W0xa9zdwdLtfOrV5YXOZ2Gt7aFli8ts7yi46SOS+brB2H+FGvdjwysT8dW3mehMyukUCx1o/hSTSMllLRRRO9zXyZhsBQf85159JBoJ1/0dpKrayuYfaKrTz10RZSkxN48ppBTBySjoj4FHM8JWW76DZSzjTR28zXC2QbHCc37S4uo2VKEiJw95tr6ZCWwpVnprN8436/Ena0DrHLLSxhytxs8vYcZtyA03jw8v60a54c1TErFes00dus7mF0IxGXl8RLT0thZeZol8nutVU7+dmIzi7P1HQn2obYlVdW89THW5i9Yiutmzbm+RvOZGz/005aJ9piVipeaKIPA+fDaHcdZbWlGHdnar66aidLs/d4PZu1VjQNsftm+0Gmzs1m64FjXH1mR+67tC8tU5N8jk2HBSoVHE30Yeapo2zhmkKP9fzaueN9KWnYMcTO35r/0YoBYh1zAAATHElEQVQqHnt/I698uYOOrVJ49bbhnNuzrdv1dVigUvbQRB8BrjrKalv6vvJW0rDj8nX+1M8/3VTEvQty2V1Sxi0ju/Cni3vT1MskZHZeNCLYjulo7dhWyhea6KOEq5KNN55KGqEaYleb4Fy1tF3tbA4dO85DS/OY/20hPU5pxtxfncOZp7fy6b3sGhYYbCevdhKrWKeJPkoEUof2VtIIdoidq/6EumrjNsbwXu5eHliUS3FpJXeO6sFvL+xBcmKCx9d3ldRDnTyD7eTVTmIV6zTRRwlP4+3TUpI4dryKyuofRusEUtLwZc4d58ePVVR5PcrokJZC0eFy7l+Uy7L1+xiQ3pJXbh1O3w4tvMYSrlZysJ282kmsYl1AV5hSoTd5TG9Skk5u/aYkJfD3awezdvrFPH7VINLTUhAcQzH9PZ3d25WRXD1eXFb/wuHOmiQ24vyebbnoyf/x6ab9TB3bhwW/OcdrkofAr7YUiGCvlBUNV9pSKhjaoo8S3urTwZY0vJUf/O0jOLV5Mi1Tk3j9m10M69qamVcMoJuLScjcCWcrOdhOXjs7iZUKB030UcTXZB7ICBBvidWfBNtIHEM9jx2v5uEJ/fnpsM5uJyFzJ5xDKUMxtXAwz1cq0jTRx5hAa9veEqu7xxsJ1NQ5kbfGgAh8cPf5ASfmcLeSgz0i0rljVCzzWqMXkRdFpEhEcp2WtRaRD0Vki/W7lbVcRORpEckXkWwRGWpn8A1RoLVtd30AtYnV3eN1k3ytiqqaoFrfE4ak8+gVA4Lqd1BK+caXFv3LwD+AV5yWZQIfG2NmikimdX8qcAnQ0/oZDjxn/VYhEmht25c+AFePP7J0A/uPVtR7vfQQlFi0laxUeHhN9MaYFSLSpc7i8cAF1u05wKc4Ev144BXjuJrJKhFJE5H2xpg9oQq4oQumtu0tsTo/Xl5ZzawPN3PgWP0krx2RSsWWQIdXnlqbvK3fp1jL04FdTusVWMvqEZFJIpIlIln79+8PMIyGx1sJJhRWbf2e8/66nH+u2Iox0KJJIq1Sk7TEolSMCnVnrKuhFy6rvMaY2cBscFxKMMRxRJX7Fubw+le7qDaGBBGuH97JrymHndk5AuRIeSUz39vIa1/tPOmLPFxeRUpSArOuHawJXqkYFGiLfp+ItAewfhdZywuATk7rdQR2Bx5e7LtvYQ6vrtp5Yg76amN4ddVO7lvo+wRmdU0Yks7KzNHMunYw4LhAyciZn5w4+SkQyzcWcfGsFbz+9U6aJSfW2zvbdTKTOwvXFDJy5id0zVwa9GdTqqELNNEvBm62bt8MLHJafpM1+mYEUNLQ6/Ovf7XL5fJXV+0MKnl5O9PVVwePHef3b6zhlpe/oXmTROb9+hyOVVS5XDdcp/yH6rMppRy8lm5E5HUcHa9tRaQAmA7MBN4SkduAncDV1urvAuOAfKAUuMWGmGOKq6tJ1QpmbpdgJ9oyxrAkew8zFq+npKyS313YkztG9aBxYqOIzwsfyknEdHphpXwbdXO9m4cudLGuAe4INqh4kuDm0oEQ3AyIwUwhsO9wOfcuyOWjDfsY2LElr90+nI17jjDqb5+yu7iMtNQkkhoJlTXBTaIWqFBNj6DTCyvloJOa2ez64Z08Pl5YXBZQSSKQibaMMbzx9U4uevJ/fJ6/n/GDOnDgSAVj//4Zd7+59kSp5FBpJYhj1sxIjLQJ1SRidkycpn0HKhbpFAg2qx1d8+qqnW7XCaSV6e8UAju+P0bmvBy+3Po9I7q15sI+p/Lkh5tPPL/uMUdltaFpciJrp1/sc0yhMnlMbybPXXfStMxJCeL3EUWoJ07TIwQVq7RFHwYPTxjA368dXG/8e61AWpm+TiFQXWP492dbGfP3FeQWlvCXiQP47y9G8PIX273OVhno0UZI1N3zBDAAN9TTC4dzamWlQklb9GFSm4B//+Zal48H0sr0dqbrpr1HmDIvm3W7irmwzyk8PLE/7Vum+PV+kWixPr5s00n9AwCVNcbv/oxQT5ymFyBRsUoTfRjVzvtu94iW41U1PPtpPs8sz6d5kySevn4Ilw1sj4icGIXiawO5rLKaGYvXh3XkSqgSaqhPLov0aCSlAqWJPszsnp537a5ips7NZtO+I1w+qAPTL+tLm2bJgG/XgHWluKzyxNWmwlGXDmVCDeXEaXoBEhWrtEYfZnZNz1t2vJqHl+RxxbMrKSmr5IWbM3j6+iEnkjy4rjHXSk9LoVVqkm/vZXNdOhzz+QRCp1ZWsUpb9BEQ6ul5v/juAJnzcth5sJSfDu9M5iV9aNGkftJ2V/oQYGXmaL9a/HbWpaP5ik46tbKKRZroY9jh8koefXcDr3+9iy5tUnn99hGc3b2N2/W9lURcJdjS41WOcfVunmMXTahKhY4m+hj1Ud4+7l2YQ9GRCpolJ7L9+1L+9PY6jy1fX2rMdROsq1Z+NJRRlFK+00QfY74/WsGMd/J4Z91u2rdsQuNGjThqTULmraM0kJJINJdRlFK+EeNh0q1wycjIMFlZWZEOI6oZY1i8bjczFq/naEUVd47qyZvf7GR3SXm9ddPTUliZOToCUSqlwklEVhtjMrytpy36GLCnpIx7F+TyycYiBndK47GrBtLr1Ob8/aPNLtfXE3iUUs400UexmhrD69/s5NF3N1JdY7jv0jO4ZWRXEho5rv+kJ/AopXyhiT5KbTtwjMx52Xy17SAje7Th0YkD6dwm9aR19AQepZQvNNHbKJCLXlRV1/DC59t48sPNNE5sxGNXDuTqjI6I1L8cr3aUKqV8oYneJoFMabthz2Gmzssmu6CEi/ueykMT+nNqiyYe30fHmyulvNFEbxN/LodXUVXNM5/k8+yn35GWmsQzPx3KuAGnuWzFK6WUvzTR28TXGRi/3XmIqXOz2VJ0lCuGpnP/pX1p1bRxOEJUSjUQQSV6EdkOHAGqgSpjTIaItAbeBLoA24FrjDGHggsz9ngbEVN6vIrHl23i5S+2075FE1665SxG9T4l3GEqpRqAUMxeOcoYM9hp0H4m8LExpifwsXW/wfE0A+PnWw4w5u8reGnldm4ccTof/OFHmuSVUraxo3QzHrjAuj0H+BSYasP7RDVXI2LuGNWdL747wFtZBXRt25S3fnk2w7q2jnCkSql4F2yiN8AHImKAfxpjZgOnGmP2ABhj9ohIg22qOo+IWbZ+L/cvzOX7Y8f59QXd+d2FPWni5hqySikVSsEm+pHGmN1WMv9QRDb6+kQRmQRMAujcuXOQYUSv/UcqmLF4PUtz9nBG+xa8cPNZDOjY8sTjgYy1V0opfwSV6I0xu63fRSKyABgG7BOR9lZrvj1Q5Oa5s4HZ4JjULJg4opExhgVrCvnzkjxKK6qZPKY3k87vRlLCD90igYy1V0opfwXcGSsiTUWkee1t4GIgF1gM3GytdjOwKNggY01hcRm3vPwNf3hrHd3aNuXd353LHaN6nJTkwfNYe6WUCpVgWvSnAgusk3oSgf8aY94XkW+At0TkNmAncHXwYcaGmhrDa1/tYOZ7GzHAjMv6cuPZXU5MQlaXr2PtlVIqGAEnemPMVmCQi+XfAxcGE1Qs2rr/KJnzcvh6+0HO69mWv0wcQKfWqR6fo7NPKqXCIRTj6Bu0quoanvv0O8Y+9Rkb9x7m8asG8sqtw7wmefA81l4ppUJFp0AIwvrdJUydl01u4WHG9juNP0/oxynNPU9C5kxnn1RKhYMm+gCUV1bzf59s4Z//20paamOe+9lQLhnQPqDX0tknlVJ200Tvp6ztB5kyL5ut+49x1Zkdue/SM0hL1UnIlFLRSxO9j45VOCYhm/Pldjq0TOGVW4dxfq92kQ5LKaW80kTvgxWb9zNtfg67S8q4acTpTBnbh6bJuumUUrFBs5UHxaXHeXjpBuauLqB7u6a8/cuzyeiik5AppWKLJno33svZw/2L1nOo9Dh3jOrOb0frJGRKqdikib6OoiPlPLBwPe+v30u/Di2Yc+tZ9OvQ0vsTlVIqSmmitxhjmLu6gIeW5FFeVcPUsX24/byuJCboOWVKqdimiR7YdbCUexbk8NmWA5zVpRUzrxxI93bNIh2WUkqFRINO9DU1hle+3M5jyzYhwJ/H9+OG4afTyM0kZEopFYsabKLPLzrK1HnZrN5xiB/1ascjE/vTsZX3+WmUUirWNLhEX1ldw+wVW3nqoy2kJifw5DWDmDgkHWu6ZaWUijsNKtHnFpYwZW42eXsOc+mA9sy4vB/tmidHOiyllLJVg0j05ZXVPPXxFmav2Errpo15/oYzGdv/tEiHpZRSYRH3if7rbQfJnJfN1gPHuCajI/eO60vL1KRIh6WUUmETt4n+SHklj72/if+s2kHHVin857ZhnNdTJyFTSjU8cZnol28q4t75Oew5XM6tI7vypzG9SG0clx9VKaW8si37ichY4CkgAfi3MWamXe9V69Cx4zy0JI/5awrpeUoz5v7qHM48vZXdb6uUUlHNlkQvIgnAM8CPgQLgGxFZbIzJs+P9jDEszdnD9EXrKSmr5K7RPbhjdA+SE3USMqWUsqtFPwzIN8ZsBRCRN4DxQMgT/b7D5dy/MJcP8vYxIL0lr/5iOGe0bxHqt1FKqZhlV6JPB3Y53S8Ahof6TZZvLOKuN9ZwvKqGe8b14daROgmZUkrVZVeid3WaqTlpBZFJwCSAzp07B/QmXds2ZWjnVsy4vB9d2zYN6DWUUire2dX8LQA6Od3vCOx2XsEYM9sYk2GMyWjXLrBhj13aNmXOrcM0ySullAd2JfpvgJ4i0lVEGgPXAYttei+llFIe2FK6McZUicidwDIcwytfNMast+O9lFJKeWbbOHpjzLvAu3a9vlJKKd/oEBWllIpzmuiVUirOaaJXSqk4p4leKaXinCZ6pZSKc2KM8b6W3UGI7Ad2BPj0tsCBEIZjt1iKN5ZihdiKN5ZihdiKN5ZiheDiPd0Y4/WM06hI9MEQkSxjTEak4/BVLMUbS7FCbMUbS7FCbMUbS7FCeOLV0o1SSsU5TfRKKRXn4iHRz450AH6KpXhjKVaIrXhjKVaIrXhjKVYIQ7wxX6NXSinlWTy06JVSSnkQ04leRMaKyCYRyReRzEjHU5eIbBeRHBFZKyJZ1rLWIvKhiGyxfkfs6uUi8qKIFIlIrtMyl/GJw9PWts4WkaFREOsMESm0tu9aERnn9Ng0K9ZNIjImnLFa799JRJaLyAYRWS8iv7OWR9329RBrVG5fEWkiIl+LyDor3get5V1F5Ctr275pTZGOiCRb9/Otx7tEQawvi8g2p2072Fpuz9+BMSYmf3BMf/wd0A1oDKwD+kY6rjoxbgfa1ln2GJBp3c4E/hrB+M4HhgK53uIDxgHv4bh62AjgqyiIdQbwJxfr9rX+HpKBrtbfSUKY420PDLVuNwc2W3FF3fb1EGtUbl9rGzWzbicBX1nb7C3gOmv588Cvrdu/AZ63bl8HvBkFsb4MXOVifVv+DmK5RX/iAuTGmONA7QXIo914YI51ew4wIVKBGGNWAAfrLHYX33jgFeOwCkgTkfbhidRtrO6MB94wxlQYY7YB+Tj+XsLGGLPHGPOtdfsIsAHHtZSjbvt6iNWdiG5faxsdte4mWT8GGA3MtZbX3ba123wucKGIuLrcaThjdceWv4NYTvSuLkDu6Y8zEgzwgYistq6RC3CqMWYPOP7BgFMiFp1r7uKL1u19p3WI+6JTGSyqYrVKBUNwtOaievvWiRWidPuKSIKIrAWKgA9xHFUUG2OqXMR0Il7r8RKgTaRiNcbUbttHrG07S0SS68ZqCcm2jeVE7/UC5FFgpDFmKHAJcIeInB/pgIIQjdv7OaA7MBjYAzxhLY+aWEWkGTAP+L0x5rCnVV0sC2vMLmKN2u1rjKk2xgzGcT3qYcAZHmKKaLx1YxWR/sA0oA9wFtAamGqtbkussZzovV6APNKMMbut30XAAhx/kPtqD8Ws30WRi9Ald/FF3fY2xuyz/olqgH/xQ/kgKmIVkSQcifM1Y8x8a3FUbl9XsUb79gUwxhQDn+KoZ6eJSO1V85xjOhGv9XhLfC8DhoxTrGOtcpkxxlQAL2Hzto3lRB/VFyAXkaYi0rz2NnAxkIsjxput1W4GFkUmQrfcxbcYuMkaFTACKKktQURKndrlRBzbFxyxXmeNtugK9AS+DnNsArwAbDDGPOn0UNRtX3exRuv2FZF2IpJm3U4BLsLRr7AcuMpare62rd3mVwGfGKvnM0KxbnTa2QuOvgTnbRv6v4Nw9T7b8YOjh3ozjvrcvZGOp05s3XCMTFgHrK+ND0dt8GNgi/W7dQRjfB3HIXkljpbEbe7iw3FI+Yy1rXOAjCiI9T9WLNnWP0h7p/XvtWLdBFwSgW17Lo5D7mxgrfUzLhq3r4dYo3L7AgOBNVZcucAD1vJuOHY4+cDbQLK1vIl1P996vFsUxPqJtW1zgVf5YWSOLX8HemasUkrFuVgu3SillPKBJnqllIpzmuiVUirOaaJXSqk4p4leKaXinCZ6pZSKc5rolVIqzmmiV0qpOPf/qws0WUevLVEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regressor = linear_model.LassoCV(alphas=np.logspace(0.01,10,10))\n",
    "regressor.fit(diabetes_X_train, diabetes_y_train)\n",
    "print(\"Best alpha:\",regressor.alpha_)\n",
    "print(\"Explained variance score:\", regressor.score(diabetes_X_test, diabetes_y_test))\n",
    "\n",
    "y_predict = regressor.predict(diabetes_X_test)\n",
    "plt.figure()\n",
    "plt.scatter(diabetes_y_test,y_predict)\n",
    "plt.plot(np.linspace(0,350,100),np.linspace(0,350,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "1. Build a [Bayesian ridge](https://scikit-learn.org/stable/modules/linear_model.html#bayesian-ridge-regression) regression model (available as `sklearn.linear_models.BayesianRidge`) and fit the diabetes dataset with it.\n",
    "2. What is the explained variance score you get with it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "Setting regularisation parameters or controlling model complexity in a frequentist setting can be achieved using cross validation. Scikit learn implements a nice interface for cross validation and to optimize hyperparameters. \n",
    "\n",
    "To fully exploit cross validation, we need to use cross validation iterators, available in the module `sklearn.model_selection`. These are objects that generate the proper splits of the train dataset. Examples are:\n",
    "* `KFold` is for k fold cross validation, use `n_splits` to set the number of splits.\n",
    "* `RepeatedKFold`, like k-fold, but repeated `n_repeats` times. By setting `random_state` we can replicat experiments. \n",
    "* `LeaveOneOut` is for leave one out  (LOO) cross validation. In terms of accuracy, LOO often results in high variance as an estimator for the test error, and 5- or 10- fold cross validation should be preferred to LOO, though if the learning curve is steep for the training size in question, then 5- or 10- fold cross validation can overestimate the generalization error.\n",
    "* `ShuffleSplit` generates a user defined number of independent train / test dataset splits, with the test size specified by the option `test_size`. Samples are first shuffled and then split into a pair of train and test sets.\n",
    "It is possible to control the randomness for reproducibility of the results by explicitly seeding the `random_state` pseudo random number generator.\n",
    "* `StratifiedKFold` it's like `KFold`, but using stratified sampling, i.e. it preserves the percentage of samples of each target class as the complete set.\n",
    "\n",
    "The previous methods work with i.i.d. data, an assumption violated if the underlying generative process yield groups of dependent samples (i.e. medical data collected from multiple patients, with multiple samples taken from each patient). In this case, if we know the group for each data point, we can use `GroupKFold` or `LeaveOneGroupOut`. See the Scikit-learn [documentation](http://scikit-learn.org/stable/modules/cross_validation.html) for further details. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set = [2 3]; test_set = [0 1]\n",
      "train set = [0 1]; test_set = [2 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "kf_cv = model_selection.KFold(n_splits=2)\n",
    "for train, test in kf_cv.split(['a','b','c','d']):\n",
    "    print(\"train set = {}; test_set = {}\".format(train, test))\n",
    "#see the KFold outputs indices of train and test sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform cross validation on a specific estimator, we can use the `cross_val_score` function, which takes as input:\n",
    "1. an estimator\n",
    "2. train and test datasets\n",
    "3. a cross_validation iterator, with the option `cv`\n",
    "4. a scoring criterion, with the option `scoring`.\n",
    "\n",
    "The method computes the scores for a fixed value of hyperparameters!\n",
    "\n",
    "The function `cross_val_predict` has a similar interface to cross_val_score, but returns, for each element in the input, the prediction that was obtained for that element when it was in the test set. Only cross-validation strategies that assign all elements to a test set exactly once can be used (otherwise, an exception is raised)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SV score: 0.47988368563401884  0.047263511492239334\n",
      "predicted: 199.36071746534853 - true 151.0\n",
      "predicted: 70.04088214670878 - true 75.0\n",
      "predicted: 172.36396726559903 - true 141.0\n",
      "predicted: 160.9666310530091 - true 206.0\n",
      "predicted: 127.41797122030346 - true 135.0\n"
     ]
    }
   ],
   "source": [
    "scoring = ['explained_variance', 'neg_mean_squared_error', 'neg_mean_absolute_error', 'r2']\n",
    "regressor = linear_model.Ridge(alpha=0.1)\n",
    "kf_cv = model_selection.KFold(n_splits=5)\n",
    "\n",
    "\n",
    "scores = model_selection.cross_val_score(regressor, diabetes.data, diabetes.target, scoring='r2',cv=kf_cv)\n",
    "print(\"SV score:\", scores.mean(),\"\",scores.std())\n",
    "\n",
    "regressor = linear_model.Ridge(alpha=0.1)\n",
    "prediction = model_selection.cross_val_predict(regressor, diabetes.data, diabetes.target, cv=kf_cv)\n",
    "for i in range(5):\n",
    "    print(\"predicted:\",prediction[i],\"- true\",diabetes.target[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimizing hyperparameters with cross-validation\n",
    "In order to optimize parameters, we can rely on built-in methods in the `model_selection` module, which perform either grid search or random search. The first explores all hyperparameters combinations ona  grid (can explote computationally), which the second performs random search, exploring only a fixed subset of random points. \n",
    "\n",
    "Which are the hyperparameters of an estimator? We can get them using `estimator.get_params()` method. \n",
    "\n",
    "A search consists of:\n",
    "* an estimator (regressor or classifier such as sklearn.svm.SVC());\n",
    "* a parameter space, specified as a dictionary or list of dictionaries;\n",
    "* a method for searching or sampling candidates;\n",
    "* a cross-validation scheme; \n",
    "* a score function.\n",
    "\n",
    "`GridSearchCV` performs the grid search, while `RandomizedSearchCV` does the randomised search, and requires also the specification of a computational budget using the `n_iter` options. The option `n_jobs=-1` uses maximum number of parallel threads/ processes to perform the CV search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "regressor = linear_model.Ridge()\n",
    "parameters = {'alpha':np.logspace(-5,2,8)}\n",
    "score = 'r2'\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    "clf = model_selection.GridSearchCV(regressor, parameters,cv=kf,scoring=score,n_jobs=-1)\n",
    "clf.fit(diabetes.data, diabetes.target)\n",
    "print(clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48229 (+/-0.099) for {'alpha': 1e-05}\n",
      "0.48229 (+/-0.098) for {'alpha': 0.0001}\n",
      "0.48228 (+/-0.098) for {'alpha': 0.001}\n",
      "0.48140 (+/-0.097) for {'alpha': 0.01}\n",
      "0.47982 (+/-0.095) for {'alpha': 0.1}\n",
      "0.41004 (+/-0.090) for {'alpha': 1.0}\n",
      "0.13822 (+/-0.072) for {'alpha': 10.0}\n",
      "-0.00478 (+/-0.073) for {'alpha': 100.0}\n"
     ]
    }
   ],
   "source": [
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.5f (+/-%0.3f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0004484248092278032}\n",
      "0.48230 (+/-0.098) for {'alpha': 0.0002872203185757912}\n",
      "0.48229 (+/-0.098) for {'alpha': 3.252787333653604e-05}\n",
      "0.48229 (+/-0.098) for {'alpha': 0.0007352854500039751}\n",
      "0.48230 (+/-0.098) for {'alpha': 0.0006111173787326436}\n",
      "0.48230 (+/-0.098) for {'alpha': 0.0004484248092278032}\n",
      "0.48229 (+/-0.098) for {'alpha': 0.0006741445730269782}\n",
      "0.48230 (+/-0.098) for {'alpha': 0.0002743505287122642}\n",
      "0.48228 (+/-0.098) for {'alpha': 0.0010500855848706698}\n",
      "0.48224 (+/-0.098) for {'alpha': 0.0014502726394160408}\n",
      "0.48229 (+/-0.098) for {'alpha': 3.3307354083868405e-05}\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "regressor = linear_model.Ridge()\n",
    "#note, for randomised search we pass a continuous distribution for continuos parameters.\n",
    "parameters = {'alpha': stats.expon(scale=0.001)}\n",
    "score = 'r2'\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    "clf = model_selection.RandomizedSearchCV(regressor, parameters,cv=kf,scoring=score,n_jobs=-1,n_iter = 10)\n",
    "clf.fit(diabetes.data, diabetes.target)\n",
    "print(clf.best_params_)\n",
    "\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.5f (+/-%0.3f) for %r\" % (mean, std * 2, params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "Classification is a task similar to regression in Scikit-learn, we just need to instantiate the proper objects. \n",
    "`LogisticRegression` is probably the most famous classifier, and in Scikit-learn comes with a built-in regularization L2 regularization. `C` here control the regularization strenght, but the larger it is the less regularization! L1 penalty can be set by `penalty='l1'` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logistic = linear_model.LogisticRegression(C=1e5)\n",
    "logistic.fit(iris_X_train, iris_y_train)\n",
    "print(\"Classification accuracy:\",logistic.score(iris_X_test,iris_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many classification algorithms in Scikit-learn, like nearest neighbours, decision trees, support vector machines, and many others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "neigh_class = neighbors.KNeighborsClassifier(n_neighbors=5, weights=\"distance\")\n",
    "neigh_class.fit(iris_X_train, iris_y_train)\n",
    "print(\"Classification accuracy:\",neigh_class.score(iris_X_test,iris_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy (linear): 0.9666666666666667\n",
      "Classification accuracy (poly): 0.9666666666666667\n",
      "Classification accuracy (rbf): 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svc = svm.SVC(kernel='linear', C = 1, gamma='auto')\n",
    "svc.fit(iris_X_train, iris_y_train)    \n",
    "print(\"Classification accuracy (linear):\", svc.score(iris_X_test,iris_y_test))\n",
    "\n",
    "svc = svm.SVC(kernel='poly', degree=3, gamma='auto')\n",
    "svc.fit(iris_X_train, iris_y_train)    \n",
    "print(\"Classification accuracy (poly):\", svc.score(iris_X_test,iris_y_test))\n",
    "\n",
    "\n",
    "svc = svm.SVC(kernel='rbf',C=1.0, gamma='auto')\n",
    "svc.fit(iris_X_train, iris_y_train)    \n",
    "print(\"Classification accuracy (rbf):\", svc.score(iris_X_test,iris_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When specifying a parameter space for grid (or random) search, we can also pass a list of dictionaries, like in the following set of parameters for SVC. \n",
    "```\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "1. Run cross validation with SVM on rbf and poly kernel, trying to improve over basic results, playing with the regulariser `C`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Scoring\n",
    "Scikit-learn implements many different ways of scoring models, both for regression, classification, clustering, etc. \n",
    "You can find a detailed list and discussion in the [online reference](http://scikit-learn.org/stable/modules/model_evaluation.html).\n",
    "\n",
    "* **Estimator score** method: each estimators has a default score method, see each estimators documentation.\n",
    "* **Scoring parameter**: cross-validation rely on an internal scoring strategy. One can pass a predefined Scorer object, or a custom scorer, maybe obtained from a metrics. \n",
    "* **Metric functions**: the `metrics` module implements functions assessing prediction error for specific purposes. \n",
    "\n",
    "In the list of predefined scores, and also in metrics, particularly for multi-class classification, there are some attributes that govern how binary classification is used to score the multi-class case (e.g. `f1`,`f1_micro`,`f1_macro`,`f1_weighted`,`f1_samples`).\n",
    "* `macro` simply calculates the mean of the binary metrics, giving equal weight to each class. In problems where infrequent classes are nonetheless important, macro-averaging may be a means of highlighting their performance. On the other hand, the assumption that all classes are equally important is often untrue, such that macro-averaging will over-emphasize the typically low performance on an infrequent class.\n",
    "* `weighted` accounts for class imbalance by computing the average of binary metrics in which each classs score is weighted by its presence in the true data sample.\n",
    "* `micro` gives each sample-class pair an equal contribution to the overall metric (except as a result of sample-weight). Rather than summing the metric per class, this sums the dividends and divisors that make up the per-class metrics to calculate an overall quotient. Micro-averaging may be preferred in multilabel settings, including multiclass classification where a majority class is to be ignored.\n",
    "* `samples` applies only to multilabel problems. It does not calculate a per-class measure, instead calculating the metric over the true and predicted classes for each sample in the evaluation data, and returning their (sample_weight-weighted) average.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: accuracy : 0.9733333333333334  0.04422166387140532\n",
      "score: precision_macro : 0.9793650793650794  0.0331438301870176\n",
      "score: recall_macro : 0.9733333333333333  0.04422166387140534\n",
      "score: f1_macro : 0.9726430976430975  0.0456897053283\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = model_selection.cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "print(\"score:\",\"accuracy\",\":\",scores.mean(),\"\",scores.std())\n",
    "\n",
    "scorers = ['precision_macro','recall_macro','f1_macro']\n",
    "for sc in scorers:\n",
    "    scores = model_selection.cross_val_score(clf, iris.data, iris.target, cv=10, scoring=sc)\n",
    "    print(\"score:\",sc,\":\",scores.mean(),\"\",scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make your own scorer\n",
    "An alternativa to predifined scorer objects is to generate a custom one, likely starting from a function in the  module `sklearn.metrics`. We can convert them using the `make_scorer` method. Note that the following convention on functions of  `sklearn.metrics` apply:\n",
    "* functions ending with `_score` return a value to maximize, the higher the better.\n",
    "* functions ending with `_error` or `_loss` return a value to minimize, the lower the better. When converting into a scorer object, set the `greater_is_better` parameter to `False`.\n",
    "\n",
    "\n",
    "As an example we will craft a F-beta scorer, with beta equal to 2. The F-beta score is the weighted harmonic mean of precision and recall, reaching its optimal value at 1 and its worst value at 0. The beta parameter determines the weight of precision in the combined score. beta < 1 lends more weight to precision, while beta > 1 favors recall (beta -> 0 considers only precision, beta -> inf only recall). This roeks for a two class problem. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM, score: 0.9310344827586207\n",
      "Linear SVM, best params: {'C': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "ftwo_scorer = metrics.make_scorer(metrics.fbeta_score, beta=2)\n",
    "grid = model_selection.GridSearchCV(svm.SVC(kernel='linear'), cv=5, param_grid={'C': np.logspace(-1,3,5)}, scoring=ftwo_scorer)\n",
    "#make a random dataset for testing\n",
    "X, y = datasets.make_classification(n_samples=200)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "clf = grid.fit(X_train,y_train)\n",
    "clf.fit(X_train,y_train)\n",
    "print(\"Linear SVM, score:\",clf.score(X_test,y_test))\n",
    "print(\"Linear SVM, best params:\",clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.94      0.94      0.94        31\n",
      "     class 1       0.93      0.93      0.93        29\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        60\n",
      "   macro avg       0.93      0.93      0.93        60\n",
      "weighted avg       0.93      0.93      0.93        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this is a nice summary for classification\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(metrics.classification_report(y_test, clf.predict(X_test), target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction\n",
    "When working with high-dimensional data, it can be a clever idea to try to reduce dimensionality. The most common approach is PCA, which finds the best linear projection of data Ii.e. the one explaining most of the variance).  \n",
    "\n",
    "PCA in Scikit-learn is in the module `decomposition`, and it can be used to transform/ preprocess data (also in pipelines, see below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance: [4.15315584 1.45165929 1.19026215 0.95486802 0.6528035  0.60970791\n",
      " 0.51562004 0.4155897 ]\n",
      "Noise variance: 0.043318293213964645\n",
      "Explained variance: 0.3498995449169452\n"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "pca = decomposition.PCA(n_components = 8,whiten=True)\n",
    "pca.fit(diabetes_X_train)\n",
    "print(\"Explained variance:\",pca.explained_variance_)\n",
    "print(\"Noise variance:\",pca.noise_variance_)\n",
    "\n",
    "\n",
    "regressor = linear_model.Ridge(alpha=0.1)\n",
    "regressor.fit(pca.transform(diabetes_X_train),diabetes_y_train)\n",
    "print(\"Explained variance:\",regressor.score(pca.transform(diabetes_X_test),diabetes_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelining\n",
    "Pipeline can be used to chain multiple estimators into one. This is useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification. All estimators in a pipeline, except the last one, must be transformers (i.e. must have a transform method). The last estimator may be any type (transformer, classifier, etc.).\n",
    "\n",
    "Pipeline serves two purposes here:\n",
    "* **Convenience and encapsulation:** fit and predict need to be called only once on the data.\n",
    "* **Joint parameter selection:** to grid search over parameters of all estimators in the pipeline at once.\n",
    "* **Safety:** to avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance: 0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        16\n",
      "  versicolor       0.85      0.96      0.90        23\n",
      "   virginica       0.94      0.81      0.87        21\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        60\n",
      "   macro avg       0.93      0.92      0.92        60\n",
      "weighted avg       0.92      0.92      0.92        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import pipeline\n",
    "estimators = [('scaler', preprocessing.StandardScaler()), ('clf', svm.SVC(kernel='rbf',gamma=1.0,C=1.0))]\n",
    "pipe = pipeline.Pipeline(estimators)\n",
    "pipe.fit(iris_X_train,iris_y_train)\n",
    "\n",
    "y_predict = pipe.predict(iris_X_test)\n",
    "print(\"Explained variance:\",pipe.score(iris_X_test,iris_y_test))\n",
    "\n",
    "print(metrics.classification_report(iris_y_test, y_predict, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1.0, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the way to refer to parameters of each estimator\n",
    "pipe.set_params(clf__C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1.0, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this accesses the estimator\n",
    "pipe.named_steps['clf']\n",
    "# use pipe.steps[0] for step 0 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 1.2400000000000002, 'clf__gamma': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        16\n",
      "  versicolor       0.88      0.96      0.92        23\n",
      "   virginica       0.95      0.86      0.90        21\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        60\n",
      "   macro avg       0.94      0.94      0.94        60\n",
      "weighted avg       0.94      0.93      0.93        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpaz/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#why this behaves so strangely?\n",
    "param_grid = dict(clf__C=np.linspace(0.1,2,11), clf__gamma=[0.5,1,1.5,2,2.5])\n",
    "grid = model_selection.GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring = \"f1_macro\")\n",
    "clf = grid.fit(iris_X_train,iris_y_train)\n",
    "print(grid.best_params_)\n",
    "clf.fit(iris_X_train,iris_y_train)\n",
    "y_predict = clf.predict(iris_X_test)\n",
    "print(metrics.classification_report(iris_y_test, y_predict , target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 1.4300000000000002, 'clf__gamma': 0.5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        20\n",
      "  versicolor       0.95      0.95      0.95        20\n",
      "   virginica       0.95      0.95      0.95        20\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        60\n",
      "   macro avg       0.97      0.97      0.97        60\n",
      "weighted avg       0.97      0.97      0.97        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The above warnings seem to happen because the train and test sets are unbalanced.\n",
    "\n",
    "param_grid = dict(clf__C=np.linspace(0.1,2,11), clf__gamma=[0.5,1,1.5,2,2.5])\n",
    "grid = model_selection.GridSearchCV(pipe, param_grid=param_grid, scoring = \"f1_macro\",\n",
    "                                    cv=5)\n",
    "clf = grid.fit(iris_X_train2, iris_y_train2)\n",
    "print(grid.best_params_)\n",
    "y_predict = clf.predict(iris_X_test2)\n",
    "print(metrics.classification_report(iris_y_test2, y_predict , target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercises\n",
    "\n",
    "1. Fetch the california housing dataset using scikit-learn datasets module and convert it into a pandas.DataFrame. Explore the correlations between the target and the rest of the features using seaborn visualizations. Are there redundant features? What features show the largest linear correlation with target? Do you think they are the most informative features?\n",
    "\n",
    "2. Transform the target continous values into quartile labels (discrete values that indicate if the given target value is in the lowest 25% of all values, 25 to 50 %, etc). Repeat the visual exploration with seaborn visualizations. From this visualization, can you identify features that are non-linearly correlated with the target? Are they the same features that showed the highest linear correlation too?\n",
    "\n",
    "3. Interpretation question: Explore through visualizations the relationship between Latitude, Longitude and the continuous target value (Hint, try to also overlay the locations of San Francisco, Reno, Los Angeles, San Diego and Sacramento over the data). Is the target value homogenuously distributed across California? If there is heterogeneity, how could one exploit the knowledge of Latitude and Longitude to improve the model's predictions?\n",
    "#### The California dataset is too big to use the SVC on all of it in a short time. We will work on the subset of data that is around San Francisco (374600N 1222600O)\n",
    "\n",
    "4. Get the dataset that has the Latitude and Longitude inside a box, 0.6 degrees wide, centered at San Francisco (374600N 1222600O).\n",
    "\n",
    "5. Build an SVC using linear and RBF kernels to learn the target value using only the MedInc, HouseAge and AveRooms features. Which kernel works best?\n",
    "\n",
    "6. Repeat the same as above but using only the Population, AveOccup, Latitude and Longitude features. Which kernel works best?\n",
    "\n",
    "7. Repeat the same as above but with all features. Which kernel works best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Hints for solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Help for Ex 1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "\n",
    "# To get the dataset use datasets.fetch_california_housing\n",
    "raw_data = datasets.fetch_california_housing()\n",
    "\n",
    "# Create the dataframe\n",
    "df = pd.DataFrame(data=raw_data['data'],\n",
    "                  columns=raw_data['feature_names'])\n",
    "df = df.assign(target=raw_data['target'])\n",
    "print(df.head(4))\n",
    "sns.pairplot(data=df)\n",
    "\n",
    "# To explore the linear correlation, you can use the pearson\n",
    "# correlation defined by np.corrcoef\n",
    "plt.figure()\n",
    "plt.bar(range(len(raw_data['feature_names'])),\n",
    "        np.corrcoef(df.values.T)[-1, :-1])\n",
    "plt.gca().set_xticks(range(len(raw_data['feature_names'])))\n",
    "plt.gca().set_xticklabels(raw_data['feature_names'], rotation=60)\n",
    "plt.ylabel('Pearson correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Help for Ex 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "\n",
    "# To get the dataset use datasets.fetch_california_housing\n",
    "raw_data = datasets.fetch_california_housing()\n",
    "\n",
    "# To split into percentiles you can use numpy.percentile\n",
    "# with digitize or just a plain sort too\n",
    "target = raw_data['target']\n",
    "bins = np.percentile(target, np.linspace(0, 100, 5)[1:])\n",
    "bins[-1] += 1\n",
    "target = np.digitize(target, bins)\n",
    "\n",
    "# Create the dataframe\n",
    "df = pd.DataFrame(data=raw_data['data'],\n",
    "                  columns=raw_data['feature_names'])\n",
    "df = df.assign(target=target)\n",
    "print(df.head(4))\n",
    "\n",
    "# Colorcode according to the target\n",
    "sns.pairplot(data=df,\n",
    "             hue='target'\n",
    "            )\n",
    "\n",
    "# To explore the linear correlation, you can use the pearson\n",
    "# correlation defined by np.corrcoef\n",
    "plt.figure()\n",
    "plt.bar(range(len(raw_data['feature_names'])),\n",
    "        np.corrcoef(df.values.T)[-1, :-1])\n",
    "plt.gca().set_xticks(range(len(raw_data['feature_names'])))\n",
    "plt.gca().set_xticklabels(raw_data['feature_names'], rotation=60)\n",
    "plt.ylabel('Pearson correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hints for Ex 3\n",
    "plt.figure(figsize=(9, 9))\n",
    "sns.relplot(data=df, x='Longitude', y='Latitude', hue='target', alpha=0.4, kind='scatter')\n",
    "sns.jointplot(data=df, x='Longitude', y='Latitude', kind='kde', n_levels=40)\n",
    "\n",
    "def digitize(a, bins=10):\n",
    "    a = np.asarray(a).flatten()\n",
    "    m = np.min(a)\n",
    "    M = np.max(a)\n",
    "    bins = np.linspace(m, M, bins + 1)\n",
    "    bins[-1] += 1 # To prevent np.digitize from assinging M to a separate bin\n",
    "    return np.digitize(a, bins) - 1\n",
    "\n",
    "\n",
    "def crude_geomerge(lat, lon, val, bins=10,\n",
    "                   val_name='Value', reduce=np.mean):\n",
    "    lat = np.asarray(lat)\n",
    "    lon = np.asarray(lon)\n",
    "    val = np.asarray(val)\n",
    "    blat = digitize(lat, bins)\n",
    "    blon = digitize(lon, bins)\n",
    "    df = pd.DataFrame.from_dict({'blat': blat,\n",
    "                                 'blon': blon,\n",
    "                                 'Latitude': lat,\n",
    "                                 'Longitude': lon,\n",
    "                                 val_name: val,\n",
    "                                })\n",
    "    def reducer(df, cols=None, reduce_=np.mean):\n",
    "        if cols is None:\n",
    "            cols = [c for c in df.columns\n",
    "                    if c not in ['blat', 'blon']]\n",
    "        output = (df.groupby(['blat', 'blon'])[cols].\n",
    "                     apply(reduce_)\n",
    "                 )\n",
    "        if isinstance(output, pd.Series):\n",
    "            output = output.to_frame(name=cols[0])\n",
    "        return output\n",
    "\n",
    "    cols1 = [c for c in df.columns\n",
    "             if c not in ['blat', 'blon', val_name]]\n",
    "    return pd.concat([reducer(df, cols1),\n",
    "                      reducer(df, [val_name], reduce)\n",
    "                     ], axis=1).reset_index(drop=True)\n",
    "\n",
    "bins = 40\n",
    "\n",
    "df2 = crude_geomerge(df.Latitude,\n",
    "                     df.Longitude,\n",
    "                     df.target,\n",
    "                     bins=bins,\n",
    "                     val_name='target')\n",
    "sns.relplot(data=df2, x='Longitude', y='Latitude', hue='target',\n",
    "            kind='scatter', alpha=0.7)\n",
    "plt.title('Mean of target')\n",
    "\n",
    "df2 = crude_geomerge(df.Latitude,\n",
    "                     df.Longitude,\n",
    "                     df.target,\n",
    "                     bins=bins,\n",
    "                     val_name='target',\n",
    "                     reduce=np.median)\n",
    "sns.relplot(data=df2, x='Longitude', y='Latitude', hue='target',\n",
    "            kind='scatter', alpha=0.7)\n",
    "plt.title('Median of target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Help for Ex 4\n",
    "\n",
    "# We can use simple boolean indexing\n",
    "SF_lat = 37 + 46. / 60 \n",
    "SF_lon = -122 + 26. /60\n",
    "valid = np.logical_and(np.abs(df.Latitude - SF_lat) < 0.3,\n",
    "                       np.abs(df.Longitude - SF_lon) < 0.3)\n",
    "print(np.sum(valid), len(df), np.mean(valid))\n",
    "SF = df[valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Help for Ex 5, 6 and 7\n",
    "\n",
    "# It is best to Scale the entire dataset first, and then divide in train and test\n",
    "# What is a good scaler when the data has outliers?\n",
    "X = SF[[c for c in SF.columns if c != 'target']].values\n",
    "target = SF['target'].values\n",
    "scaled_X = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "# Define the estimators either as Pipelines or raw SVCs\n",
    "\n",
    "# To get faster results, we can increase the cache_size (beware of RAM usage)\n",
    "rbf = svm.SVC(kernel='rbf', gamma='auto', C=1,\n",
    "              cache_size=4000)\n",
    "lin = svm.SVC(kernel='linear', C=1,\n",
    "              cache_size=4000)\n",
    "\n",
    "# If necessary you can split into train and test sets using\n",
    "# stratify to ensure that the proportion of targets are\n",
    "# preserved between each set\n",
    "train_X, test_X, train_y, test_y = \\\n",
    "    model_selection.train_test_split(X, target,\n",
    "                                     test_size=0.5)\n",
    "\n",
    "# To split the features you can use simple slicing\n",
    "f1_train_X = train_X[:, :4]\n",
    "f1_test_X = train_X[:, :4]\n",
    "\n",
    "print(train_X.shape)\n",
    "# Use KFold crossvalidation with gridsearch if necessary.\n",
    "# Choose an appropriate evaluation metric too\n",
    "lin.fit(train_X, train_y)\n",
    "pred_y = lin.predict(test_X)\n",
    "metrics.f1_score(pred_y, test_y, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
